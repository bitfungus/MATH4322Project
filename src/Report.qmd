---
title: "Modeling Year-Over-Year Changes in Global Lithium Production"
author: "Klarissa Castillo, Paulo Cataquis, Diego Coroando, Cameron Htut, Syrus Tolentino"
date: today
date-format: long
format:
#  beamer: 
#    code-block-border-left: "#245ABE"
#    highlight-style: github
  pdf:
#    include-in-header: preamble.tex
    pdf-engine: pdflatex
    documentclass: scrartcl
    colorlinks: true
    highlight-style: github
    mainfont: "Times New Roman"
    sansfont: "Open Sans"
    monofont: "Fira Code"
    monofontoptions: "Scale=0.8"
    cite-method: biblatex
    biblio-style: apa
    biblio-title: "References"
    geometry:
      - top=25mm
      - bottom=25mm
      - left=30mm
      - right=25mm
      - heightrounded
bibliography: ./references.bib
csl: apa.csl
execute:
  echo: true
  warning: false
  message: false
packages:
  - randomForest
  - tidyVerse
  - glue
---


```{r include=FALSE, echo=FALSE, results='hide'}
# THIS IS TO LOAD THE DATA STUFF TO NOT NECESSARILY INCLUDE INTO OUR REPORT BUT RATHER
# TO MAKE THE PLOT RENDERINGS WORK

library(glue)
library(randomForest)
library(tidyverse) # for ggplot
library(caret)

set.seed(123)


cwd <- "/home/diego/Downloads/FinalReport/src" # change this to your cwd where the dataset is in
df <- read_csv(glue("{cwd}/data/lithium-production.csv")) 

# Postprocessing
df_global <- df %>%
  group_by(Year) %>%
  summarise(Production = sum(lithium_production_kt, na.rm = TRUE)) %>%
  filter(Year >=  1995 & Year <= 2023)

df_global$Year_c <- df_global$Year - 1995
```




# Introduction
There are a lot of resources on Earth for energy applications and storage, but not many can also be applied to medicine or textiles. One that stands prevalent is lithium, a non-renewable metal resource. With the majority of lithium products being batteries for cars, electronics, and energy storage; as well as medication for bipolar disorders, lithium serves a multitude of applications. In the past couple decades, due to its various applications, the supply, demand, and consumption of lithium has soared. Due to its finite nature, we ask ourselves, how has global production for this commodity changed annually and what can we infer about future lithium production.  

To do this, we analyzed global lithium production data from 2019 to 2024, collected from the U.S. Geological Survey (USGS). The data includes 540 observations from four variables:  

- Entity -- The country of origin of Lithium
- Code -- Country Code
- Year - The year recorded per observation
- Lithium Production (KT) - Numerical value of lithium extracted (in KiloTonnes)

**Input Variable**: `Year` (centered as `year_c`)

**Response Variable**: `production` (global production in KT)



```{=latex}
\begin{center}

\textbf{Primary Question:}

How has total world lithium production changed year over year?

\end{center}
```

# Methods and Results

## Linear Regression Model (Paulo, Klarissa)

To understand how global lithium production has changed year over year, we applied a Linear Regression Model. Our response variable is Production, representing total worldwide lithium output in kilotons. The predictor we used was Year_c, a centered version of the calendar year (Year - 2019). This transformation improves interpretability by aligning the intercept with the base year 2019. We selected linear regression because it is one of the most interpretable and reliable models for analyzing simple time-based trends. In our case, we were not only interested in predicting values but also in estimating the average change in lithium production per year. Some advantages are that they are simple and fast to compute, produce a direct slope estimate for a year over year change, and easy to interpret in real world terms. Disadvantages are that they assume a constant linear relationship between the predictor and response, it can underfit when the data includes sudden changes or nonlinear jumps and are sensitive to outliers like our drop in 2024 

The linear regression formula would be:

$$
 \text{Production} = \beta_0 + \beta_1 \cdot \text{Year\_c} 
$$

We considered only one predictor: Year_c. Additional predictors like price, country reserves, or imports were excluded because the dataset has only six observations, and adding more variables would drastically increase the risk of overfitting. Our goal was to assess the trend in global production, not build a multivariate explanatory model. Including more predictors would have required testing their p-values for significance, and with such a small sample size, those values would likely be unstable and unreliable. Thus, linear regression with a single predictor was the most appropriate approach for our research question and data limitations.

In each iteration, we randomly selected 80% of the data to serve as the training set and used the remaining 20% as the test set. The model was fit on the training data using the formula [Equation] which predicts global lithium production based solely on the centered year variable. After training the model, we generated predictions for the test set and calculated the root mean squared error (RMSE) between the predicted and actual production values. This process was repeated across 10 different random splits, and we recorded the RMSE from each run. We used a fixed random seed (set.seed(123)) to ensure reproducibility of the results. This approach provided a robust estimate of how well the model generalizes to unseen data while mitigating the randomness associated with a single split. The average test RMSE across the 10 iterations was approximately 383,598.8 kilotons, suggesting that the model’s typical prediction error is around 383,000 kilotons. Given the very small size of the dataset (n = 6) and the presence of an outlier in the 2024 estimate, this result is acceptable and demonstrates the model’s capacity to capture the general trend in lithium production over time. 

```{r results="hide", echo=FALSE}
rmse_list = rep(0, 10)

for (i in 1:10){
  train_index <- sample(1:nrow(df_global), size = 0.8 * nrow(df_global))
  train_data <- df_global[train_index, ]
  test_data <- df_global[-train_index, ]
  
  lm_model <- lm(Production ~ Year_c, data = train_data)
  
  predictions <- predict(lm_model, newdata = test_data)
  
  rmse <- sqrt((mean(test_data$Production - predictions)^2))
  rmse_list[i] <- rmse
}

glue("Mean Test RMSE: {mean(rmse_list)}")
```

## Tree Based Methods (Cameron, Diego, Syrus)

**Decision Trees**

To explore alternative modeling approaches beyond linear regression, we first considered decision trees. A decision tree recursively splits the data into regions based on threshold values of the predictor. The flexibility given by tree-based methods allowed the decision tree to capture nonlinear patterns that a linear model might miss, even with only one predictor.

However, a limitation of decision trees is their instability. Small changes in the data can lead to large changes in the tree structure. This was especially problematic in our dataset, which contained few observations and includes an anomaly in 2024 due to missing U.S. data. This kind of sensitivity often results in overfitting and poor generalization.

The followings plot shows predicted values vs. actual production, that show the model’s step-like predictions that fail to capture the smooth upward trend in production. Additionally, we visualized the cross-validation deviance and resulting pruned tree to demonstrate its instability.

```{r, echo=FALSE, fig.width=6, fig.height=4, fig.align="center", dpi=300, fig.cap="Decision Tree Predictions vs Actual Production. The model fails to capture smooth trends and introduces abrupt shifts."}

library(tree)
RMSE_decision_tree = rep(0, 10)
for (i in 1:10){
  train_idx = sample(1:nrow(df_global), size = 0.8 * nrow(df_global))
  train_data <- df_global[train_idx, ]
  test_data <- df_global[-train_idx, ]
  
  tree_model <- tree(Production ~ Year, data = df_global, subset = train_idx)
  
  yhat = predict(tree_model, newdata=test_data)
  RMSE_decision_tree[i] = sqrt(mean(as.numeric(test_data$Production) - as.numeric(yhat))^2) 
}

```

```{r, echo=FALSE, fig.width=6, fig.height=4, fig.align="center", dpi=300, fig.cap="Decision Tree Predictions vs Actual Production. The model fails to capture smooth trends and introduces abrupt shifts due to its limited depth and sensitivity to splits."}

tree_model <- tree(Production ~ Year_c, data = df_global)
df_global$pred_tree <- predict(tree_model)

ggplot(df_global, aes(x = Year)) +
geom_point(aes(y = Production), size = 3) +
geom_line(aes(y = pred_tree), color = "orange", size = 1) +
labs(y = "Lithium Production (kilotonnes)",
title = "Decision Tree Predictions vs Actual") +
theme_minimal()

```

```{r, echo=FALSE, fig.width=6, fig.height=4, fig.align="center", dpi=300, fig.cap="Cross-validation deviance for various tree sizes. Smaller trees may generalize better, but deviance remains high, indicating poor fit."}
cv_tree <- cv.tree(tree_model)
plot(cv_tree$size, cv_tree$dev, type = "b", ylab = "Deviance", xlab = "Tree Size")
```

```{r, echo=FALSE, fig.width=6, fig.height=4, fig.align="center", dpi=300, fig.cap="Pruned decision tree (size = 2). Despite pruning, the model captures only coarse patterns and misses gradual production trends."}

pruned_tree <- prune.tree(tree_model, best = 2)
plot(pruned_tree)
text(pruned_tree, pretty = 0)
```

**Random Forests**

To address these limitations, we used a *Random Forest*, an ensemble method that fits multiple decision trees on different bootstrapped subsets of the data and averages their predictions. This improves the model's stability while also retaining the flexibility to capture nonlinear patterns.

We trained a Random Forest using 5-fold cross-validation and tested various `ntree` values (number of trees) to find the best trade-off between bias and variance. The optimal model minimized RMSE and produced smooth, accurate predictions, in contrast to the abrupt, unstable predictions of the standalone tree.


```{r echo=FALSE, results="hide"}
# HIDE THIS ITS JUST TO GET THE DATA READY AND NOT SHOW THE CODE BLOCK

train_ctrl <- trainControl(method = "cv", number = 5)
ntree_vals <- c(100,200,300,400,500,600,700,800,900,1000)
rmse_vals_ntree <- numeric(length(ntree_vals))

for(i in seq_along(ntree_vals)){
  rf_tmp <- train(
    Production ~ Year_c,
    data = df_global,
    method = "rf",
    trControl = trainControl(method = "cv", number = 5),
    ntree = ntree_vals[i]
  )
  rmse_vals_ntree[i] <- min(rf_tmp$results$RMSE)
}

(rmse_ntree_df <- data.frame(ntree = ntree_vals, RMSE = rmse_vals_ntree))

best_ntree <- rmse_ntree_df[which.min(rmse_ntree_df$RMSE), ]$ntree

rf_model <- train(Production ~ Year_c, data = df_global, method = "rf",
                  trControl = train_ctrl, ntree = best_ntree)

df_global$pred_rf <- predict(rf_model, df_global)
```

```{r, echo=FALSE, fig.width=6, fig.height=4, fig.align="center", fig.cap="Root Mean Squared Error (RMSE) vs Number of Trees in Random Forest. RMSE values fluctuate accross different `nree` settings, with the best performance at 800 trees. This suggesets some instability due to the small dataset, but tuning ntree can still yield performance gains"}

ggplot(rmse_ntree_df, aes(x = ntree, y = RMSE)) +
  geom_line() +
  geom_point() +
  theme_minimal() +
  labs(
    x = "Number of Trees (ntree)",
    y = "RMSE",
    title = "Tuning Random Forest: ntree vs RMSE"
  )
```


```{r, echo=FALSE, fig.width=6, fig.height=4, fig.align="center", fig.cap="Random Forest Predictions vs. Actual Lithium Production. Compared to the decision tree, this model produces smoother and more accurate estimates of production across years."}

ggplot(df_global, aes(x = Year)) +
  geom_point(aes(y = Production), size = 3) +
  geom_line(aes(y = pred_rf), color = "darkgreen", size = 1) +
  labs(
    title = "Random Forest Predicted vs Actual Lithium Production",
    y = "Production (kilotonnes)"
  ) +
  theme_minimal()
```


In summary, while the decision tree provided insight into nonlinear trends, its instability made it a poor-fit model for the dataset that we were using. While, the random forest model retained the interpretability of tree-based methods while offering much greater predictive accuracy. This demonstrated that ensemble methods like random forests are better for capturing smooth, real-world trends in global lithium production. Especially when working with small, noisy datasets such as our case.

# Results
Results

# Conclusion (Klarissa)
In conclusion, we can draw attention to our original question and address how world lithium production changes year over year and what we can conclude about future lithium resources. Our analysis of global lithium production from 2019 to 2024 revealed a clear upward trend in annual output, emphasizing lithium’s growing importance as a nonrenewable resource critical to energy storage and electrification technologies. 


Using a linear regression model as our primary analytical tool, we have found that production has increased every year with high statistical significance. This model effectively answered our research question and aligned closely with real world expectations of increasing lithium demand. Among the models tested, including decision trees and random forests, the linear regression model offered the most interpretable and actionable insight. The simplicity and clarity of the linear model made it best suited for this small dataset and our research objectives. Its transparent coefficients and consistent performance highlighted a strong, time driven increase in production, which policymakers and industry leaders could use to inform resource planning in regard to economic and environmental strategies.


However, we do also acknowledge limitations in our work. The dataset included only six years of data, and these gaps limit long term forecasting precision and make the model sensitive to anomalies such as the dip observed in 2024, which is likely due to incomplete or estimated data rather than a true production drop. 


However, our project still reinforces the urgency of addressing lithium’s finite availability and suggests that predictive modeling, even with limited data, can inform environmental and economic policy decisions regarding critical minerals. 


Overall, the conclusion about our dataset of choice can draw focus on the economic and environmental impacts of lithium production and depletion. As a finite, nonrenewable resource, lithium has a growing demand for electric vehicles, energy storage and consumer electronics. Our analysis shows that production has steadily increased year over year, highlighting lithium’s rising market value and importance. This upward trend also raises concerns about long term resource scarcity and the ecological consequences of expanded mining. These findings emphasize the need for sustainable extraction practices, investment in recycling technologies, and exploration of alternative materials. 

# References




